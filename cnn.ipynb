{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "https://towardsdatascience.com/using-neural-networks-for-a-functional-connectivity-classification-of-fmri-data-ff0999057bc6"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_matrices(data_dir, file_suffix=None, zscore=False):\n",
    "    \"\"\"\n",
    "    Reads in a set of individual-subject connectivity matrices stored in data_dir,\n",
    "    \n",
    "    Returns a dataframe that is subjects x edges (by vectorizing the upper triangle of each FC matrix).\n",
    "    \n",
    "    Assumes:\n",
    "    - each matrix is stored in a separate file beginning with the subject ID, and\n",
    "    - matrices are symmetric (squareform); i.e., for a parcellation with 268 nodes, matrices should be 268 x 268\n",
    "    \"\"\"\n",
    "    \n",
    "    all_fc_data = {}\n",
    "    for subj in glob.glob(data_dir + \"*.txt\"):\n",
    "        # try to find this subject's matrix\n",
    "        file = subj\n",
    "\n",
    "        \n",
    "        # read it in and make sure it's symmetric and has reasonable dimensions\n",
    "        tmp = np.loadtxt(file,  delimiter=',')\n",
    "        assert tmp.shape[0]==tmp.shape[1]>1, \"Matrix seems to have incorrect dimensions: {}\".format(tmp.shape)\n",
    "        subject = next((s for s in file.split(\"/\")[-1].split('.') if file_suffix in s), None) # returns 'AMBAC070' por exemplo\n",
    "\n",
    "        # take just the upper triangle and store it in a dictionary\n",
    "        if ~zscore:\n",
    "            all_fc_data[subject] = tmp[np.triu_indices_from(tmp, k=1)]\n",
    "        if zscore:\n",
    "            all_fc_data[subject] = sp.stats.zscore(tmp[np.triu_indices_from(tmp, k=1)])\n",
    "    \n",
    "    \n",
    "    # Convert dictionary into dataframe\n",
    "    all_fc_data = pd.DataFrame.from_dict(all_fc_data, orient='index')\n",
    "    \n",
    "    return all_fc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"correlation_matrix/\"\n",
    "all_fc_data = read_in_matrices(path, file_suffix='AMBAC')\n",
    "all_fc_data = all_fc_data.reset_index().drop_duplicates(subset='index', keep='last').set_index('index').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_behav_data = pd.read_csv('resultado_AMBAC.csv', dtype={'Subject': str})\n",
    "all_behav_data.set_index('fmri_code', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_behav_data = all_behav_data.loc[all_behav_data.index.intersection(all_fc_data.index)]\n",
    "all_fc_data = all_fc_data.loc[all_fc_data.index.intersection(all_behav_data.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData = all_behav_data.merge(all_fc_data, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 0         1         2         3         4         5  \\\n",
       "AMBAC002  0.224453  0.026833 -0.115072 -0.107804 -0.119077  0.098518   \n",
       "AMBAC005  0.359312  0.246687  0.556772  0.121289 -0.180004  0.382876   \n",
       "AMBAC006  0.534393  0.111283 -0.173513 -0.025006 -0.092542 -0.051647   \n",
       "AMBAC007  0.493204  0.056914  0.352139 -0.098430  0.106770 -0.038427   \n",
       "AMBAC009  0.739659  0.361713  0.579131 -0.021446  0.034835  0.496933   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "AMBAC091  0.575746  0.456343  0.356181  0.118814  0.435038  0.378848   \n",
       "AMBAC098  0.639946  0.270302  0.368711  0.079681  0.237024  0.015285   \n",
       "AMBAC098  0.639946  0.270302  0.368711  0.079681  0.237024  0.015285   \n",
       "AMBAC099  0.385947  0.264924  0.385979  0.159520  0.493245  0.129837   \n",
       "AMBAC101  0.720886  0.532520  0.507985  0.240646  0.164969  0.401586   \n",
       "\n",
       "                 6         7         8         9  ...      6660      6661  \\\n",
       "AMBAC002 -0.013074  0.008957  0.054643  0.249948  ...  0.529677  0.000000   \n",
       "AMBAC005  0.260317  0.033281 -0.264635  0.423935  ...  0.760304  0.000000   \n",
       "AMBAC006 -0.068786  0.103325 -0.325004  0.455359  ...  0.586871  0.097291   \n",
       "AMBAC007  0.311217 -0.132460  0.026979  0.228928  ...  0.848102  0.000000   \n",
       "AMBAC009  0.539170  0.062104  0.146481  0.656779  ...  0.755872  0.000000   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "AMBAC091  0.338086  0.312840  0.164663  0.441674  ...  0.727718  0.471780   \n",
       "AMBAC098  0.204195  0.255182  0.249228  0.556441  ...  0.605168  0.090958   \n",
       "AMBAC098  0.204195  0.255182  0.249228  0.556441  ...  0.605168  0.090958   \n",
       "AMBAC099  0.132703  0.016750  0.312444  0.463667  ...  0.706635  0.233334   \n",
       "AMBAC101  0.506771  0.224316  0.439136  0.621582  ...  0.574441  0.155988   \n",
       "\n",
       "              6662      6663      6664      6665      6666      6667  \\\n",
       "AMBAC002  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "AMBAC005  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "AMBAC006  0.000000  0.042744  0.134844  0.000000  0.021347  0.000000   \n",
       "AMBAC007  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "AMBAC009  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "AMBAC091  0.328402  0.273524  0.629722  0.456215  0.315639  0.491840   \n",
       "AMBAC098 -0.050603 -0.170203  0.228583  0.181728 -0.118766  0.184700   \n",
       "AMBAC098 -0.050603 -0.170203  0.228583  0.181728 -0.118766  0.184700   \n",
       "AMBAC099  0.066247  0.069966  0.331490 -0.071436  0.005219  0.252227   \n",
       "AMBAC101  0.021552 -0.152379  0.156590 -0.038150 -0.445519  0.450542   \n",
       "\n",
       "              6668      6669  \n",
       "AMBAC002  0.000000  0.000000  \n",
       "AMBAC005  0.000000  0.000000  \n",
       "AMBAC006  0.168665  0.000000  \n",
       "AMBAC007  0.000000  0.000000  \n",
       "AMBAC009  0.000000  0.000000  \n",
       "...            ...       ...  \n",
       "AMBAC091  0.372266  0.591903  \n",
       "AMBAC098  0.090116  0.139310  \n",
       "AMBAC098  0.090116  0.139310  \n",
       "AMBAC099  0.018923  0.499058  \n",
       "AMBAC101  0.100517  0.329826  \n",
       "\n",
       "[63 rows x 6670 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>6660</th>\n      <th>6661</th>\n      <th>6662</th>\n      <th>6663</th>\n      <th>6664</th>\n      <th>6665</th>\n      <th>6666</th>\n      <th>6667</th>\n      <th>6668</th>\n      <th>6669</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AMBAC002</th>\n      <td>0.224453</td>\n      <td>0.026833</td>\n      <td>-0.115072</td>\n      <td>-0.107804</td>\n      <td>-0.119077</td>\n      <td>0.098518</td>\n      <td>-0.013074</td>\n      <td>0.008957</td>\n      <td>0.054643</td>\n      <td>0.249948</td>\n      <td>...</td>\n      <td>0.529677</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>AMBAC005</th>\n      <td>0.359312</td>\n      <td>0.246687</td>\n      <td>0.556772</td>\n      <td>0.121289</td>\n      <td>-0.180004</td>\n      <td>0.382876</td>\n      <td>0.260317</td>\n      <td>0.033281</td>\n      <td>-0.264635</td>\n      <td>0.423935</td>\n      <td>...</td>\n      <td>0.760304</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>AMBAC006</th>\n      <td>0.534393</td>\n      <td>0.111283</td>\n      <td>-0.173513</td>\n      <td>-0.025006</td>\n      <td>-0.092542</td>\n      <td>-0.051647</td>\n      <td>-0.068786</td>\n      <td>0.103325</td>\n      <td>-0.325004</td>\n      <td>0.455359</td>\n      <td>...</td>\n      <td>0.586871</td>\n      <td>0.097291</td>\n      <td>0.000000</td>\n      <td>0.042744</td>\n      <td>0.134844</td>\n      <td>0.000000</td>\n      <td>0.021347</td>\n      <td>0.000000</td>\n      <td>0.168665</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>AMBAC007</th>\n      <td>0.493204</td>\n      <td>0.056914</td>\n      <td>0.352139</td>\n      <td>-0.098430</td>\n      <td>0.106770</td>\n      <td>-0.038427</td>\n      <td>0.311217</td>\n      <td>-0.132460</td>\n      <td>0.026979</td>\n      <td>0.228928</td>\n      <td>...</td>\n      <td>0.848102</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>AMBAC009</th>\n      <td>0.739659</td>\n      <td>0.361713</td>\n      <td>0.579131</td>\n      <td>-0.021446</td>\n      <td>0.034835</td>\n      <td>0.496933</td>\n      <td>0.539170</td>\n      <td>0.062104</td>\n      <td>0.146481</td>\n      <td>0.656779</td>\n      <td>...</td>\n      <td>0.755872</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>AMBAC091</th>\n      <td>0.575746</td>\n      <td>0.456343</td>\n      <td>0.356181</td>\n      <td>0.118814</td>\n      <td>0.435038</td>\n      <td>0.378848</td>\n      <td>0.338086</td>\n      <td>0.312840</td>\n      <td>0.164663</td>\n      <td>0.441674</td>\n      <td>...</td>\n      <td>0.727718</td>\n      <td>0.471780</td>\n      <td>0.328402</td>\n      <td>0.273524</td>\n      <td>0.629722</td>\n      <td>0.456215</td>\n      <td>0.315639</td>\n      <td>0.491840</td>\n      <td>0.372266</td>\n      <td>0.591903</td>\n    </tr>\n    <tr>\n      <th>AMBAC098</th>\n      <td>0.639946</td>\n      <td>0.270302</td>\n      <td>0.368711</td>\n      <td>0.079681</td>\n      <td>0.237024</td>\n      <td>0.015285</td>\n      <td>0.204195</td>\n      <td>0.255182</td>\n      <td>0.249228</td>\n      <td>0.556441</td>\n      <td>...</td>\n      <td>0.605168</td>\n      <td>0.090958</td>\n      <td>-0.050603</td>\n      <td>-0.170203</td>\n      <td>0.228583</td>\n      <td>0.181728</td>\n      <td>-0.118766</td>\n      <td>0.184700</td>\n      <td>0.090116</td>\n      <td>0.139310</td>\n    </tr>\n    <tr>\n      <th>AMBAC098</th>\n      <td>0.639946</td>\n      <td>0.270302</td>\n      <td>0.368711</td>\n      <td>0.079681</td>\n      <td>0.237024</td>\n      <td>0.015285</td>\n      <td>0.204195</td>\n      <td>0.255182</td>\n      <td>0.249228</td>\n      <td>0.556441</td>\n      <td>...</td>\n      <td>0.605168</td>\n      <td>0.090958</td>\n      <td>-0.050603</td>\n      <td>-0.170203</td>\n      <td>0.228583</td>\n      <td>0.181728</td>\n      <td>-0.118766</td>\n      <td>0.184700</td>\n      <td>0.090116</td>\n      <td>0.139310</td>\n    </tr>\n    <tr>\n      <th>AMBAC099</th>\n      <td>0.385947</td>\n      <td>0.264924</td>\n      <td>0.385979</td>\n      <td>0.159520</td>\n      <td>0.493245</td>\n      <td>0.129837</td>\n      <td>0.132703</td>\n      <td>0.016750</td>\n      <td>0.312444</td>\n      <td>0.463667</td>\n      <td>...</td>\n      <td>0.706635</td>\n      <td>0.233334</td>\n      <td>0.066247</td>\n      <td>0.069966</td>\n      <td>0.331490</td>\n      <td>-0.071436</td>\n      <td>0.005219</td>\n      <td>0.252227</td>\n      <td>0.018923</td>\n      <td>0.499058</td>\n    </tr>\n    <tr>\n      <th>AMBAC101</th>\n      <td>0.720886</td>\n      <td>0.532520</td>\n      <td>0.507985</td>\n      <td>0.240646</td>\n      <td>0.164969</td>\n      <td>0.401586</td>\n      <td>0.506771</td>\n      <td>0.224316</td>\n      <td>0.439136</td>\n      <td>0.621582</td>\n      <td>...</td>\n      <td>0.574441</td>\n      <td>0.155988</td>\n      <td>0.021552</td>\n      <td>-0.152379</td>\n      <td>0.156590</td>\n      <td>-0.038150</td>\n      <td>-0.445519</td>\n      <td>0.450542</td>\n      <td>0.100517</td>\n      <td>0.329826</td>\n    </tr>\n  </tbody>\n</table>\n<p>63 rows Ã— 6670 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "mergedData.columns = mergedData.columns.astype(str)\n",
    "\n",
    "mergedData.loc[:,'0':'6669']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(mergedData.loc[:,'0':'6669'], mergedData['Group_cat'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b13814ead426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(32, activation='tanh', kernel_initializer='random_normal', input_shape=connectivity_biomarkers['correlation'].shape[1:]))\n",
    "#Second Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "#Third Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the model\n",
    "classifier.compile(optimizer = Adam(lr =.0001),loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the model\n",
    "classifier.fit(np.array(X_train),np.array(y_train), batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model=classifier.evaluate(np.array(X_train), np.array(y_train))\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test,batch_size=32)\n",
    "y_pred =(y_pred>0.5)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)\n"
   ]
  }
 ]
}